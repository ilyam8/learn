------|:----------|:----|
| alarms.status | a dimension per alarm representing the latest status of the alarm. | status |
| alarms.values | a dimension per alarm representing the latest collected value of the alarm. | value |



## Alerts

There are no alerts configured by default for this integration.


## Setup

### Prerequisites

No action required.

### Configuration

#### File

The configuration file name for this integration is `python.d/alarms.conf`.


You can edit the configuration file using the `edit-config` script from the
Netdata [config directory](/docs/configuring/configuration#the-netdata-config-directory).

```bash
cd /etc/netdata 2>/dev/null || cd /opt/netdata/etc/netdata
sudo ./edit-config python.d/alarms.conf
```
#### Options

There are 2 sections:

* Global variables
* One or more JOBS that can define multiple different instances to monitor.

The following options can be defined globally: priority, penalty, autodetection_retry, update_every, but can also be defined per JOB to override the global values.

Additionally, the following collapsed table contains all the options that can be configured inside a JOB definition.

Every configuration JOB starts with a `job_name` value which will appear in the dashboard, unless a `name` parameter is specified.


<details><summary>Config options</summary>

| Name | Description | Default | Required |
|:----|:-----------|:-------|:--------:|
| url | Netdata agent alarms endpoint to collect from. Can be local or remote so long as reachable by agent. | http://127.0.0.1:19999/api/v1/alarms?all | True |
| status_map | Mapping of alarm status to integer number that will be the metric value collected. | {"CLEAR": 0, "WARNING": 1, "CRITICAL": 2} | True |
| collect_alarm_values | set to true to include a chart with calculated alarm values over time. | False | True |
| alarm_status_chart_type | define the type of chart for plotting status over time e.g. 'line' or 'stacked'. | line | True |
| alarm_contains_words | A "," separated list of words you want to filter alarm names for. For example 'cpu,load' would filter for only alarms with "cpu" or "load" in alarm name. Default includes all. |  | True |
| alarm_excludes_words | A "," separated list of words you want to exclude based on alarm name. For example 'cpu,load' would exclude all alarms with "cpu" or "load" in alarm name. Default excludes None. |  | True |
| update_every | Sets the default data collection frequency. | 10 | False |
| priority | Controls the order of charts at the netdata dashboard. | 60000 | False |
| autodetection_retry | Sets the job re-check interval in seconds. | 0 | False |
| penalty | Indicates whether to apply penalty to update_every in case of failures. | yes | False |
| name | Job name. This value will overwrite the `job_name` value. JOBS with the same name are mutually exclusive. Only one of them will be allowed running at any time. This allows autodetection to try several alternatives and pick the one that works. |  | False |

</details>

#### Examples

##### Basic

A basic example configuration.

```yaml
jobs:
  url: 'http://127.0.0.1:19999/api/v1/alarms?all'

```
##### Advanced

An advanced example configuration with multiple jobs collecting different subsets of alarms for plotting on different charts.
"ML" job will collect status and values for all alarms with "ml_" in the name. Default job will collect status for all other alarms.


<details><summary>Config</summary>

```yaml
ML:
  update_every: 5
  url: 'http://127.0.0.1:19999/api/v1/alarms?all'
  status_map:
    CLEAR: 0
    WARNING: 1
    CRITICAL: 2
  collect_alarm_values: true
  alarm_status_chart_type: 'stacked'
  alarm_contains_words: 'ml_'

Default:
  update_every: 5
  url: 'http://127.0.0.1:19999/api/v1/alarms?all'
  status_map:
    CLEAR: 0
    WARNING: 1
    CRITICAL: 2
  collect_alarm_values: false
  alarm_status_chart_type: 'stacked'
  alarm_excludes_words: 'ml_'

```
</details>



## Troubleshooting

### Debug Mode

To troubleshoot issues with the `alarms` collector, run the `python.d.plugin` with the debug option enabled. The output
should give you clues as to why the collector isn't working.

- Navigate to the `plugins.d` directory, usually at `/usr/libexec/netdata/plugins.d/`. If that's not the case on
  your system, open `netdata.conf` and look for the `plugins` setting under `[directories]`.

  ```bash
  cd /usr/libexec/netdata/plugins.d/
  ```

- Switch to the `netdata` user.

  ```bash
  sudo -u netdata -s
  ```

- Run the `python.d.plugin` to debug the collector:

  ```bash
  ./python.d.plugin alarms debug trace
  ```


